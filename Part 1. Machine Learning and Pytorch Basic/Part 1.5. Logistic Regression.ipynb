{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 1.5. Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SXpOYmzWKEr",
        "colab_type": "text"
      },
      "source": [
        "# Part 1.5. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p1WC-WKYs7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9ipgQwbXT5z",
        "colab_type": "text"
      },
      "source": [
        "## 1. Logistic Regression\n",
        "데이터 개수가 `m`이고 차원이 `d`인 입력 **X**에 크기가 `d`인 벡터 **W**를 곱하여 크기가 `m`인 **출력**을 구한다. 이 출력을 **sigmoid 함수**에 넣어준 결과가 Logistic Regression의 결과 값이다.\n",
        "\n",
        "\n",
        "$$H(x) = P(X = 1|W) = 1 - P(X = 0|W) = \\frac{1}{1+e^{-X\\cdot W}}$$\n",
        "\n",
        "$$cost(W) = -\\frac{1}{m}\\sum y\\cdot\\log_{}{(H(x))}+(1-y)\\cdot\\log_{}{(1 - H(x))}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3F-im0iYyZH",
        "colab_type": "text"
      },
      "source": [
        "## 2. Implementation in Pytorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfBsDIpjY5LF",
        "colab_type": "text"
      },
      "source": [
        "### 2.1. Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeJr76QtWFV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xy = np.loadtxt('diabetes.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = xy[:, 0:-1]\n",
        "y_data = xy[:, [-1]]\n",
        "\n",
        "x_train = torch.FloatTensor(x_data)   # (759, 8)\n",
        "y_train = torch.FloatTensor(y_data)   # (759, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH7xN80sbdTO",
        "colab_type": "text"
      },
      "source": [
        "### 2.2. Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPlsBihmbg_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(8, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.sigmoid(self.linear(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwlfUWoYcZZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BinaryClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHuvAVQubQ5H",
        "colab_type": "text"
      },
      "source": [
        "### 2.3. Optimizer Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVd_h06mbXgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvxNKYzwcmsl",
        "colab_type": "text"
      },
      "source": [
        "### 2.4. Iteration Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "femE34RYcqEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "0cd32d24-3522-40fd-8564-e8958ba2e08a"
      },
      "source": [
        "nb_epochs = 100\n",
        "\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  hypothesis = model(x_train)\n",
        "  cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "    correct_prediction = prediction.float() == y_train\n",
        "    accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
        "\n",
        "    print(\"Epoch {:4d}/{} cost: {:.6f} accuracy: {:2.2f}%\".format(epoch, nb_epochs, cost.item(), accuracy*100))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/100 cost: 0.644366 accuracy: 67.85%\n",
            "Epoch   10/100 cost: 0.564504 accuracy: 69.30%\n",
            "Epoch   20/100 cost: 0.535280 accuracy: 73.78%\n",
            "Epoch   30/100 cost: 0.517216 accuracy: 76.02%\n",
            "Epoch   40/100 cost: 0.505415 accuracy: 77.21%\n",
            "Epoch   50/100 cost: 0.497354 accuracy: 77.73%\n",
            "Epoch   60/100 cost: 0.491652 accuracy: 77.47%\n",
            "Epoch   70/100 cost: 0.487505 accuracy: 77.34%\n",
            "Epoch   80/100 cost: 0.484419 accuracy: 76.68%\n",
            "Epoch   90/100 cost: 0.482079 accuracy: 77.34%\n",
            "Epoch  100/100 cost: 0.480275 accuracy: 77.08%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}