{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Part 1.1. Tensor Manipulation.ipynb의 사본","provenance":[{"file_id":"https://github.com/CoodingPenguin/boostcourse-dl-pytorch/blob/master/Part%201.%20Machine%20Learning%20and%20Pytorch%20Basic/Part%201.1.%20Tensor%20Manipulation.ipynb","timestamp":1583564834702}],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uogPEKRzs9tu","colab_type":"text"},"source":["# Part 1.1. Tensor Manipulation"]},{"cell_type":"code","metadata":{"id":"FE6yJ4x_s9tw","colab_type":"code","colab":{}},"source":["import torch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oriel8KHs9t0","colab_type":"text"},"source":["## 1. Vector, Matrix and Tensor\n","`1D`를 vector, `2D`를 matrix, `3D`를 tensor라고 부른다. `4D`는 tensor를 위로, `5D`는 `4D`를 옆으로, `6D`는 `5D`를 위로 확장한 것이다.\n","\n","<img src=\"https://github.com/CoodingPenguin/boostcourse-dl-pytorch/blob/master/Part%201.%20Machine%20Learning%20and%20Pytorch%20Basic/img/1-1.png?raw=1\" width=600px>"]},{"cell_type":"markdown","metadata":{"id":"8KQJq7Ios9t1","colab_type":"text"},"source":["## 2. Pytorch Tensor Shape Convention\n","어떤 모양의 tensor 든 간에 `1D`는 **batch size** 즉, 데이터의 개수를 말한다. 그리고 `2D`부터 해당 데이터가 어떻게 생겼는지를 설명한다. \n","\n","* `2D Tensor` : $|t| = (batch size, dim)$ 데이터 개수가 batch size만큼 있으며, 차원(=벡터의 크기)는 dim이다.\n","* `3D Tensor Vision` : $|t| = (batch size, width, height)$ 데이터 개수가 batch size만큼 있으며, 이미지의 너비가 width, 높이가 height이다.\n","* `3D Tensor NLP` : $|t| = (batch size, length, dim)$ 데이터 개수가 batch size만큼 있으며, 문장의 길이가 length이며, 각 단어의 차원은 dim이다."]},{"cell_type":"markdown","metadata":{"id":"VTuaDQ92s9t2","colab_type":"text"},"source":["## 3. Pytorch Tensor\n","* `dim()` : 차원\n","* `shape`, `size()` : 모양"]},{"cell_type":"code","metadata":{"id":"ANfBuu1Eud2D","colab_type":"code","outputId":"f327e88f-760d-4a5a-b3ad-e2c01629c889","executionInfo":{"status":"ok","timestamp":1583564896620,"user_tz":-540,"elapsed":3595,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}},"colab":{"base_uri":"https://localhost:8080/","height":161}},"source":["# 1차원 벡터\n","t = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\n","\n","print(t)\n","print(t.dim())\n","print(t.shape)\n","print(t.size())\n","print(t[0], t[1], t[-1])\n","print(t[2:5], t[4:-1])\n","print(t[:2], t[3:])\n","print(t[:])"],"execution_count":2,"outputs":[{"output_type":"stream","text":["tensor([0., 1., 2., 3., 4., 5., 6.])\n","1\n","torch.Size([7])\n","torch.Size([7])\n","tensor(0.) tensor(1.) tensor(6.)\n","tensor([2., 3., 4.]) tensor([4., 5.])\n","tensor([0., 1.]) tensor([3., 4., 5., 6.])\n","tensor([0., 1., 2., 3., 4., 5., 6.])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"apOfluk5vpNZ","colab_type":"text"},"source":["2차원 부터는 인덱스 안에 `:`이 있다면 해당 차원을 없앤다. 즉, 한 차원을 줄인다고 받아들이면 쉽다."]},{"cell_type":"code","metadata":{"id":"SvWp1F1Nuy8O","colab_type":"code","outputId":"7abec1e3-3b64-46a8-8687-d006e8cef3aa","executionInfo":{"status":"ok","timestamp":1583564896621,"user_tz":-540,"elapsed":3592,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["# 2차원 행렬\n","t = torch.FloatTensor([[1., 2., 3.],\n","                      [4., 5., 6.],\n","                      [7., 8., 9.],\n","                      [10., 11., 12.]])\n","\n","print(t)\n","print(t.dim())\n","print(t.shape)\n","print(t.size())\n","print(t[:, 1])\n","print(t[:, 1].size())\n","print(t[:, :-1])\n","print(t[1, :])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["tensor([[ 1.,  2.,  3.],\n","        [ 4.,  5.,  6.],\n","        [ 7.,  8.,  9.],\n","        [10., 11., 12.]])\n","2\n","torch.Size([4, 3])\n","torch.Size([4, 3])\n","tensor([ 2.,  5.,  8., 11.])\n","torch.Size([4])\n","tensor([[ 1.,  2.],\n","        [ 4.,  5.],\n","        [ 7.,  8.],\n","        [10., 11.]])\n","tensor([4., 5., 6.])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uT4qE0AhwKz2","colab_type":"text"},"source":["## 4. Broadcasting\n","연산 시에 크기(=모양)이 다르다면 자동적으로 사이즈를 맞춰주는 기능을 말한다."]},{"cell_type":"code","metadata":{"id":"Sk3F8GmHwWPd","colab_type":"code","outputId":"0dd45b20-010d-4e6d-991b-fdaf52a15a96","executionInfo":{"status":"ok","timestamp":1583564896622,"user_tz":-540,"elapsed":3589,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["m1 = torch.FloatTensor([[3, 3]])  # |m1| = (1, 2)\n","m2 = torch.FloatTensor([[2, 2]])  # |m2| = (1, 2)\n","print(m1 + m2)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["tensor([[5., 5.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uKIWvayAwivl","colab_type":"code","outputId":"c8df29d4-9a8f-49cc-da9a-ecd83b9d9a60","executionInfo":{"status":"ok","timestamp":1583564896622,"user_tz":-540,"elapsed":3585,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["m1 = torch.FloatTensor([[1, 2]])  # |m1| = (1, 2)\n","m2 = torch.FloatTensor([3])       # |m2| = (1, ) -> (1, 2)\n","print(m1 + m2)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["tensor([[4., 5.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"74IWw2sOwxIV","colab_type":"code","outputId":"66a182ed-f0bc-41c1-dc1c-b1fcd1c07016","executionInfo":{"status":"ok","timestamp":1583564896623,"user_tz":-540,"elapsed":3582,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["m1 = torch.FloatTensor([[1, 2]])    # |m1| = (1, 2) -> (2, 2)\n","m2 = torch.FloatTensor([[3], [4]])  # |m2| = (2, 1) -> (2, 2)\n","print(m1 + m2)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["tensor([[4., 5.],\n","        [5., 6.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fEry65CrxKWv","colab_type":"text"},"source":["## 5. Multiplication vs Matrix Multiplication\n","* `a.matmul(b)` : 행렬의 내적 즉, dot production\n","* `a.mul(b)` : element-wise 곱셈"]},{"cell_type":"code","metadata":{"id":"y13zs2KkxEcs","colab_type":"code","colab":{}},"source":["m1 = torch.FloatTensor([[1, 2], [3, 4]])  # |m1| = (2, 2)\n","m2 = torch.FloatTensor([[1], [2]])        # |m2| = (2, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8QH3afayOPF","colab_type":"code","outputId":"db34b91a-36f9-4e19-83b9-901becf8e96e","executionInfo":{"status":"ok","timestamp":1583564896889,"user_tz":-540,"elapsed":3842,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# matmul : 행렬의 내적\n","print(m1.matmul(m2))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["tensor([[ 5.],\n","        [11.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3DVPSM5Nyb06","colab_type":"code","outputId":"98471389-0f89-4a1c-ddd8-fd79323d71a8","executionInfo":{"status":"ok","timestamp":1583564896890,"user_tz":-540,"elapsed":3840,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["# mul : element-wise 곱셈\n","print(m1.mul(m2))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["tensor([[1., 2.],\n","        [6., 8.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u6U7fhJ05EuS","colab_type":"text"},"source":["## 6. Other Operators"]},{"cell_type":"markdown","metadata":{"id":"wmRYu8S3ykRu","colab_type":"text"},"source":["### 6.1. Aggregate Operators\n","전체에 대한 연산을 진행할 수 있지만 각 축마다 연산을 진행할 수 있다. 이 때 `dim`이 0일 때, 1일 때 등이 어떤 축을 말하는 건지 헷갈릴 수 있는데 그 때는 **해당 연산을 통해서 해당 축을 없앤다**는 느낌으로 받아들이면 된다."]},{"cell_type":"code","metadata":{"id":"_DtJZ8U0y9TY","colab_type":"code","outputId":"6cec053c-ce6d-44f7-f7ae-9c9dfbc6c2cb","executionInfo":{"status":"ok","timestamp":1583564896890,"user_tz":-540,"elapsed":3836,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["t = torch.FloatTensor([[1, 2, 3], [4, 5, 6]])\n","print(t.size())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["torch.Size([2, 3])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fgzg1VgUy0sF","colab_type":"code","outputId":"62fab8c5-08df-4e80-83b6-3f28d8f0c616","executionInfo":{"status":"ok","timestamp":1583564896891,"user_tz":-540,"elapsed":3833,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["# mean : 평균\n","print(t.mean())         # 전체 요소에 대한 평균\n","print(t.mean(dim=0))    # 첫 번째 차원에 대한 평균 -> (1, 3)\n","print(t.mean(dim=1))    # 두 번째 차원에 대한 평균 -> (2, 1)\n","print(t.mean(dim=-1))   # 마지막 차원에 대한 평균"],"execution_count":11,"outputs":[{"output_type":"stream","text":["tensor(3.5000)\n","tensor([2.5000, 3.5000, 4.5000])\n","tensor([2., 5.])\n","tensor([2., 5.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lE2UauItzbXz","colab_type":"code","outputId":"3e2aaa49-d243-40b3-97dc-d403c73c446f","executionInfo":{"status":"ok","timestamp":1583564896891,"user_tz":-540,"elapsed":3830,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["# sum : 합\n","print(t.sum())          # 전체 요소에 대한 합\n","print(t.sum(dim=0))     # 첫 번째 차원에 대한 합 -> (1, 3)\n","print(t.sum(dim=1))     # 두 번째 차원에 대한 합 -> (2, 1)\n","print(t.sum(dim=-1))    # 마지막 차원에 대한 합"],"execution_count":12,"outputs":[{"output_type":"stream","text":["tensor(21.)\n","tensor([5., 7., 9.])\n","tensor([ 6., 15.])\n","tensor([ 6., 15.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tt5-87fxzz5z","colab_type":"code","outputId":"59b45260-48ed-4fbb-c745-929b38be8f72","executionInfo":{"status":"ok","timestamp":1583564896892,"user_tz":-540,"elapsed":3827,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}},"colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["# max : 최대값 \n","print(t.max())\n","\n","# dim을 입력으로 넣을시 반환값으로 최대값과 최대값의 위치를 반환\n","# 인덱스를 통해 각각에 접근할 수 있음\n","print(t.max(dim=0))   # 첫 번째 차원에 대한 합 -> (1, 3)\n","print(t.max(dim=1))   # 두 번째 차원에 대한 합 -> (2, 1)\n","print(t.max(dim=-1))  # 마지막 차원에 대한 합"],"execution_count":13,"outputs":[{"output_type":"stream","text":["tensor(6.)\n","torch.return_types.max(\n","values=tensor([4., 5., 6.]),\n","indices=tensor([1, 1, 1]))\n","torch.return_types.max(\n","values=tensor([3., 6.]),\n","indices=tensor([2, 2]))\n","torch.return_types.max(\n","values=tensor([3., 6.]),\n","indices=tensor([2, 2]))\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YCkCcr3U0yeF","colab_type":"text"},"source":["### 6.2. View\n","`np.reshape`와 같은 기능을 한다. tensor의 모양을 변형할 수 있다. 변형된 tensor의 각 차원의 크기의 곱은 원래 tensor의 각 차원의 크기와 같다. 이를 통해 `-1`로 된 미지의 차원의 크기를 구할 수 있다. `-1`의 경우 가장 변동이 심한 차원 예를 들면, **batch size**와 같은 차원에 넣는다.\n"]},{"cell_type":"code","metadata":{"id":"9sawm5bF07U0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"0ae969ef-7cc5-4e03-d7b2-30d1c3346a34","executionInfo":{"status":"ok","timestamp":1583565025786,"user_tz":-540,"elapsed":606,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}}},"source":["t = torch.FloatTensor([[[0, 1, 2],\n","                        [3, 4, 5]],\n","                       [[6, 7, 8],\n","                        [9, 10, 11]]])\n","print(t.size())"],"execution_count":14,"outputs":[{"output_type":"stream","text":["torch.Size([2, 2, 3])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_tau0bJ61L1f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":251},"outputId":"51aa07ed-5672-45e1-b515-fb9271aa6560","executionInfo":{"status":"ok","timestamp":1583565207854,"user_tz":-540,"elapsed":638,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}}},"source":["tv1 = t.view([-1, 3])       # (4, 3) = 12\n","tv2 = t.view([-1, 1, 3])    # (4, 1, 3) = 12\n","\n","print(tv1)\n","print(tv1.size())\n","print(tv2)\n","print(tv2.size())"],"execution_count":16,"outputs":[{"output_type":"stream","text":["tensor([[ 0.,  1.,  2.],\n","        [ 3.,  4.,  5.],\n","        [ 6.,  7.,  8.],\n","        [ 9., 10., 11.]])\n","torch.Size([4, 3])\n","tensor([[[ 0.,  1.,  2.]],\n","\n","        [[ 3.,  4.,  5.]],\n","\n","        [[ 6.,  7.,  8.]],\n","\n","        [[ 9., 10., 11.]]])\n","torch.Size([4, 1, 3])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BFqqQlkW2EV4","colab_type":"text"},"source":["### 6.3. Squeeze\n","어떤 차원의 크기가 1인 경우 해당 차원을 없애준다. `squeeze`는 단순히 1인 차원만 제거하므로 `view`처럼 변형되 tensor의 각 차원의 크기의 곱과 원래 tensor의 각 차원의 크기의 곱과 같다."]},{"cell_type":"code","metadata":{"id":"rCSNkomo2YEa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"10db8c57-b204-4459-b458-fa0f39e61f98","executionInfo":{"status":"ok","timestamp":1583565382141,"user_tz":-540,"elapsed":603,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}}},"source":["t = torch.FloatTensor([[[0], [1], [2]]])  # (1, 3, 1)\n","\n","print(t)\n","print(t.size())"],"execution_count":17,"outputs":[{"output_type":"stream","text":["tensor([[[0.],\n","         [1.],\n","         [2.]]])\n","torch.Size([1, 3, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7CK0_yAu2yC6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"b57bf25e-bcf8-473d-a21d-29f01f5a0c6f","executionInfo":{"status":"ok","timestamp":1583565478912,"user_tz":-540,"elapsed":607,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}}},"source":["print(t.squeeze())            # (3, )\n","print(t.squeeze().size())"],"execution_count":18,"outputs":[{"output_type":"stream","text":["tensor([0., 1., 2.])\n","torch.Size([3])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a2guFEnh2-hL","colab_type":"text"},"source":["### 6.4. Unsqueeze\n","`squeeze`와 반대로 내가 원하는 차원에 1을 추가할 수 있다. 즉, 차원을 늘려준다."]},{"cell_type":"code","metadata":{"id":"YgkRulCJ3G8G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"5c3b7e9f-fb69-4043-8934-8f57193d7f7e","executionInfo":{"status":"ok","timestamp":1583565606699,"user_tz":-540,"elapsed":583,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}}},"source":["t = torch.Tensor([0, 1, 2])   # (3, )\n","\n","print(t)\n","print(t.size())"],"execution_count":20,"outputs":[{"output_type":"stream","text":["tensor([0., 1., 2.])\n","torch.Size([3])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CGbnFL1t3PoP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"outputId":"50e6d645-3dc7-407e-fee5-7dd7c49cf7df","executionInfo":{"status":"ok","timestamp":1583565696254,"user_tz":-540,"elapsed":610,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}}},"source":["print(t.unsqueeze(0))         # 첫 번째 차원에 추가 -> (1, 3)\n","print(t.unsqueeze(0).size())\n","\n","print(t.unsqueeze(1))         # 두 번째 차원에 추가 -> (3, 1)\n","print(t.unsqueeze(1).size())\n","\n","print(t.unsqueeze(-1))        # 마지막 차원에 추가  -> (3, 1)\n","print(t.unsqueeze(-1).size())"],"execution_count":22,"outputs":[{"output_type":"stream","text":["tensor([[0., 1., 2.]])\n","torch.Size([1, 3])\n","tensor([[0.],\n","        [1.],\n","        [2.]])\n","torch.Size([3, 1])\n","tensor([[0.],\n","        [1.],\n","        [2.]])\n","torch.Size([3, 1])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gtsr-6pX4B7l","colab_type":"text"},"source":["### 6.5. Type Casting\n","tensor 안의 요소들의 데이터 타입을 캐스팅 할 수 있다.\n","* `t.float()` : float 실수로 캐스팅\n","* `t.long()` : int 정수로 캐스팅"]},{"cell_type":"code","metadata":{"id":"XstjMex84g-T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"e106fdb2-d9b5-434e-bba7-aafe3911fd9a","executionInfo":{"status":"ok","timestamp":1583565942739,"user_tz":-540,"elapsed":591,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}}},"source":["lt = torch.LongTensor([1, 2, 3, 4])\n","ft = torch.FloatTensor([1., 2., 3., 4.])\n","\n","print(lt.float())\n","print(ft.long())"],"execution_count":23,"outputs":[{"output_type":"stream","text":["tensor([1., 2., 3., 4.])\n","tensor([1, 2, 3, 4])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wUwXYv214sfU","colab_type":"text"},"source":["### 6.6. Concatenate\n","이어붙이는 면의 차원이 같을 경우 tensor를 이어붙일 수 있다. `dim`을 통해 어디로 이어붙일지 설정할 수 있는데 해당 `dim`을 늘린다고 생각하면 된다."]},{"cell_type":"code","metadata":{"id":"a7WYv6Wq5lzq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":161},"outputId":"c22989c6-782e-4884-ede6-5ced7ba93177","executionInfo":{"status":"ok","timestamp":1583566333760,"user_tz":-540,"elapsed":615,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}}},"source":["ft1 = torch.FloatTensor([[1, 2], [3, 4]])   # (2, 2)\n","ft2 = torch.FloatTensor([[5, 6], [7, 8]])   # (2, 2)\n","\n","rt1 = torch.cat([ft1, ft2], dim=0)          # (4, 2)\n","rt2 = torch.cat([ft1, ft2], dim=1)          # (2, 4)\n","\n","print(rt1)\n","print(rt1.size())         \n","print(rt2)\n","print(rt2.size())"],"execution_count":25,"outputs":[{"output_type":"stream","text":["tensor([[1., 2.],\n","        [3., 4.],\n","        [5., 6.],\n","        [7., 8.]])\n","torch.Size([4, 2])\n","tensor([[1., 2., 5., 6.],\n","        [3., 4., 7., 8.]])\n","torch.Size([2, 4])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fdHpXhHS6LkY","colab_type":"text"},"source":["### 6.7. Stacking\n","`concatenate`를 더 편리하게 해준 함수이다. `dim`을 통해 어디로 쌓을지 지정할 수 있으며, default값은 0이다."]},{"cell_type":"code","metadata":{"id":"FNtR82sf63IU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"outputId":"f175f259-ce9f-4ecf-8682-dfd143250c9e","executionInfo":{"status":"ok","timestamp":1583566662151,"user_tz":-540,"elapsed":624,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}}},"source":["ft1 = torch.FloatTensor([1, 4])     # (2, )\n","ft2 = torch.FloatTensor([2, 5])     # (2, )\n","ft3 = torch.FloatTensor([3, 6])     # (2, )\n","\n","print(torch.stack([ft1, ft2, ft3]))           # (3. 2)\n","print(torch.stack([ft1, ft2, ft3]).size())\n","print(torch.stack([ft1, ft2, ft3], dim=1))    # (2, 3)\n","print(torch.stack([ft1, ft2, ft3], dim=1).size())"],"execution_count":28,"outputs":[{"output_type":"stream","text":["tensor([[1., 4.],\n","        [2., 5.],\n","        [3., 6.]])\n","torch.Size([3, 2])\n","tensor([[1., 2., 3.],\n","        [4., 5., 6.]])\n","torch.Size([2, 3])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-p8whhg07bT1","colab_type":"text"},"source":["### 6.8. Ones and Zeros\n","입력으로 받는 tensor의 크기의 새로운 tensor를 생성하여 `ones_like`는 1로, `zeros_like`는 0으로 초기화시킨다."]},{"cell_type":"code","metadata":{"id":"ktCunMMz7mJp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"887844b6-b97b-41d3-beca-e3e0713b8825","executionInfo":{"status":"ok","timestamp":1583566741887,"user_tz":-540,"elapsed":555,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}}},"source":["ft = torch.FloatTensor([[0, 1, 2], [2, 1, 0]])\n","\n","print(ft)\n","print(ft.size())"],"execution_count":29,"outputs":[{"output_type":"stream","text":["tensor([[0., 1., 2.],\n","        [2., 1., 0.]])\n","torch.Size([2, 3])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SGsVe5Rd7t8k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"d4f797f2-5c97-4e1c-cf2a-074a0a245f8b","executionInfo":{"status":"ok","timestamp":1583566756823,"user_tz":-540,"elapsed":533,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}}},"source":["print(torch.ones_like(ft))\n","print(torch.zeros_like(ft))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]])\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KHvHs5Xb7zir","colab_type":"text"},"source":["### 6.9. In-place Operation\n","연산 결과를 다른 변수가 아닌 원래 변수에 반영을 하고 싶다면 해당 operator 뒤에 `_`를 붙이면 된다."]},{"cell_type":"code","metadata":{"id":"0vaBAyTa7xmU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":161},"outputId":"494bc410-2f89-49d0-bff3-0a7425bf04ce","executionInfo":{"status":"ok","timestamp":1583566881368,"user_tz":-540,"elapsed":648,"user":{"displayName":"박소현","photoUrl":"","userId":"04890095664734078752"}}},"source":["print(ft.mul(2.))\n","print(ft)\n","print(ft.mul_(2.))\n","print(ft)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["tensor([[0., 2., 4.],\n","        [4., 2., 0.]])\n","tensor([[0., 1., 2.],\n","        [2., 1., 0.]])\n","tensor([[0., 2., 4.],\n","        [4., 2., 0.]])\n","tensor([[0., 2., 4.],\n","        [4., 2., 0.]])\n"],"name":"stdout"}]}]}