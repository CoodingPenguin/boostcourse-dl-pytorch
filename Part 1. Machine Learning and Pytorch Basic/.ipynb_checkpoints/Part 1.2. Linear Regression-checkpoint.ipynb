{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "99IXu7lO-r_W"
   },
   "source": [
    "# Part 1.2. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muTpukcV_USn"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_u2K0eIg-3I0"
   },
   "source": [
    "## 1. Data Definition\n",
    "시간에 따른 내 점수는 어떨까에 대해 한 번 예측해보자. 이 때 시간(입력)이 `x`이며, 점수(출력)가 `y`이다.\n",
    "\n",
    "![2-1.png](img/2-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvCmzUGj-fgS"
   },
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXE1fzlIEC2-"
   },
   "source": [
    "## 2. Hypothesis\n",
    "시간과 점수의 관계가 $y = Wx + b$로 표현된다고 할 때 $W$는 `weight`, $b$는 `bias`라고 한다. 학습하기 전에 다음을 꼭 해줘야 한다.\n",
    "* `weight`와 `bias`를 0으로 초기화\n",
    "* `requires_grad=True`로 하여 해당 매개변수는 **꼭 학습을 해야함**을 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ghxlF9IwEiT-",
    "outputId": "b4ae9381-6a2e-42c4-b784-cee50007969c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SNK4kd_cGoC0"
   },
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OQa_CM0WEysb"
   },
   "source": [
    "### 3.1. Compute Loss\n",
    "MSE(Mean Squared Error)를 통해 실제값($y^i$)과 예측값($H(x^i)$) 간의 오차 제곱의 평균을 구한다.\n",
    "\n",
    "$$cost(W, b) = \\frac{1}{m} \\sum_{i=1}^m (H(x^i) - y^i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8F50309nFLiC",
    "outputId": "27687c69-528d-424a-82f9-6e9149178912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fXWq55yQFzDH"
   },
   "source": [
    "### 3.2. Gradient Descent\n",
    "`torch.optim` 라이브러리를 사용해 경사하강법(Gradient Descent)로 매개변수 $W$와 $b$를 업데이트 시켜준다. 다음 과정은 경사하강법 시 꼭 거쳐가는 과정이다.\n",
    "* `zero_grad()` : 기울기를 초기화\n",
    "* `backward()` : 기울기를 계산\n",
    "* `step()` : 매개변수를 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qqZ58YmcFsAz"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([W, b], lr=0.01)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "cost.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MtPYSxtdGj17"
   },
   "source": [
    "### 3.3. Iteration Training\n",
    "위의 과정을 반복하면서 매개변수를 업데이트 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JWQtkGCG1z6"
   },
   "outputs": [],
   "source": [
    "nb_epochs = 1000\n",
    "for epoch in range(1, nb_epochs+1):\n",
    "  hypothesis = x_train * W + b\n",
    "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  cost.backward()\n",
    "  optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "VhvKmnpCHEoH",
    "outputId": "a3d5e432-08f5-404f-f9aa-91fa266d32f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9709], requires_grad=True) tensor([0.0663], requires_grad=True)\n",
      "tensor([13.8622], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(W, b)\n",
    "print(W*7 + b)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part 1.2. Linear Regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
