{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 3.6. Next Stage of CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV-E8k_Ur2RQ",
        "colab_type": "text"
      },
      "source": [
        "# Part 3.6. Next Stage of CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYUadthmr--S",
        "colab_type": "text"
      },
      "source": [
        "## 1. CNN의 활용\n",
        "\n",
        "![16-1.png](./img/16-1.png)\n",
        "\n",
        "- `classification` : 특정 사진이 어떤 **label**에 속하는지 분류\n",
        "  - DenseNet, SENet, MobileNet, SqueezeNet, AutoML(NAS, NASNet)\n",
        "- `object detection` : 사진 안에 객체를 찾고 어떤 **label**에 속하는지 분류\n",
        "- `object tracking` : 영상을 기준으로 각각의 프레임에 `detection`을 적용해서 객체를 찾고 어떤 프레임에서의 어떤 객체애 대해 전후 프레임 간의 연관 관계를 찾는 것. **프레임 별로 객체를 추적해나가는 것**.\n",
        "  - MDNet, GOTURN, CFNet, ROLO, Tracking the Untrackable\n",
        "- `segmentation` : 배경과 객체를 분할시켜 객체가 차지하는 영역을 찾는 것\n",
        "  - FCN, U-Net, Mask RCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM0VN3BguqG6",
        "colab_type": "text"
      },
      "source": [
        "## 2. 그 외에 여러 분야들\n",
        "`Classification`, `Detection`, `Tracking`, `Segmentation`, `Image Captioning` (RNN 필수), `Super Resolution`, `Generative Model(AutoEncoder, GAN)`, `OpenPose`"
      ]
    }
  ]
}