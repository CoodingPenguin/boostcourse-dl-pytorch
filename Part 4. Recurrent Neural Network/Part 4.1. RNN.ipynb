{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 4.1. RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ3vNaSbwzSz",
        "colab_type": "text"
      },
      "source": [
        "# Part 4.1. RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjYA_aAaxAjF",
        "colab_type": "text"
      },
      "source": [
        "## 1. RNN\n",
        "### 1.1. Sequntial Data\n",
        "RNN(Recurrent Neural Network)은 **sequential data**를 다루기 위해 만들어졌다. **sequential data**란 data의 value(값)뿐만 아니라 order(순서)까지 고려를 해야하는 데이터를 말한다.\n",
        "\n",
        "예를 들어, `hello`라는 글자를 예측하고 싶다고 할 때 `h` 다음에 `e`가 와야 하고, `e` 다음에 `l`이 와야한다. 즉, 문자의 배열 순서가 매우 중요하다. 그래야 해당 단어의 의미를 파악할 수 있기에."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP5ESdCO3daL",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. RNN Structure\n",
        "\n",
        "![17-1.png](./img/17-1.png)\n",
        "\n",
        "RNN은 모델이 순서를 이해할 수 있는 **Cell**이라는 것이 존재하는데 이 Cell 안의 학습해야할 모든 파라미터가 있으며 **해당 파라미터를 업데이트 하면서 데이터의 순서를 이해**할 수 있게 된다.\n",
        "\n",
        "또한 입력을 받으면 동일한 출력이 두 개 나오는 데 다음 입력 때 한 출력을 또 다른 입력으로 사용한다. 즉, 출력되지 않은 출력을 다음 Cell에 전달하여 사용한다. 이 때의 출력을 **hidden state**라고 한다.\n",
        "\n",
        "![17-2.png](./img/17-2.png)\n",
        "\n",
        "셀 A에서는 기본적으로 함수 연산이 일어나는데 전 단계의 hidden state와 현재 단계의 입력값을 가지고 현재 단계의 hidden state를 만든다. 각 단계 별 hidden state를 구한 뒤에 y를 위한 weight를 곱하면 우리가 원하는 예측값을 얻을 수 있다.\n",
        "\n",
        "구조가 복잡한 셀을 쓰면 좋은 성능을 낼 수 는 있으나 더 많은 학습 자원이 필요하다. 복잡도를 기준으로 `RNN`이 가장 낮고 `LSTM`이 가장 높으며 `GRU`가 그 사이 중간 정도에 위치한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qNvIGIiGNq3",
        "colab_type": "text"
      },
      "source": [
        "## 1.3. Usages of RNN\n",
        "\n",
        "![17-3.png](./img/17-3.png)\n",
        "\n",
        "* `one-to-one` : 우리가 전부터 사용하던 신경망 구조 \n",
        "* `one-to-many` : 이미지를 입력으로 넣고 해당 이미지를 설명하는 문장을 출력\n",
        "* `many-to-one` : 여러 개의 단어들 즉, 문장을 입력으로 넣으면 감정에 대한 레이블을 출력\n",
        "* `many-to-many` : 번역할 때 한 문장을 다 보고 새로운 문장을 출력\n",
        "* `many-to-many` : 비디오에서 한 프레임을 입력으로 넣고 프레임 전후의 변화를 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eetwugeRNrTC",
        "colab_type": "text"
      },
      "source": [
        "## 2. Vanilla RNN Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYJB_6LGwwT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P6mrayBN67n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1c263fd-d14a-46b3-bd5d-1376b67d962c"
      },
      "source": [
        "torch.manual_seed(0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f38929c5310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TFIigyNiOcTv",
        "colab": {}
      },
      "source": [
        "# 하이퍼 파라미터 설정\n",
        "input_size = 4\n",
        "hidden_size = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjEMawHRO-d0",
        "colab_type": "text"
      },
      "source": [
        "![17-4.png](./img/17-4.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nuo9T9tZObwV",
        "colab": {}
      },
      "source": [
        "# 각 문자를 one-hot-encoding 해줌\n",
        "# input size는 벡터의 차원 = 4\n",
        "h = [1, 0, 0, 0]\n",
        "e = [0, 1, 0, 0]\n",
        "l = [0, 0, 1, 0]\n",
        "o = [0, 0, 0, 1]\n",
        "\n",
        "# sequential data 예제\n",
        "input_data_np = np.array([[h, e, l, l, o], [e, o, l, l, l], [l, l, e, e, l]], dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9bQX5F7OlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 예제를 numpy에서 tensor로 변환\n",
        "input_data = torch.Tensor(input_data_np)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ks0FEVZPskS",
        "colab_type": "text"
      },
      "source": [
        "![17-5.png](./img/17-5.png)\n",
        "\n",
        "![17-6.png](./img/17-6.png)\n",
        "\n",
        "![17-7.png](./img/17-7.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2vLj7iTOmTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN 모델 정의\n",
        "# input만 잘 만들어주면 sequence length(5)와 batch size(3)는 알아서 계산\n",
        "rnn = torch.nn.RNN(input_size, hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsltEvjQOoln",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "86e0eb77-fb23-4ca8-f62c-b43aba7d4e66"
      },
      "source": [
        "# 결과 확인\n",
        "# input_size (3, 5, 4), output_size (3, 5, 2)\n",
        "outputs, _status = rnn(input_data)\n",
        "print(outputs)\n",
        "print(outputs.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.7497, -0.6135],\n",
            "         [-0.5282, -0.2473],\n",
            "         [-0.9136, -0.4269],\n",
            "         [-0.9136, -0.4269],\n",
            "         [-0.9028,  0.1180]],\n",
            "\n",
            "        [[-0.5753, -0.0070],\n",
            "         [-0.9052,  0.2597],\n",
            "         [-0.9173, -0.1989],\n",
            "         [-0.9173, -0.1989],\n",
            "         [-0.8996, -0.2725]],\n",
            "\n",
            "        [[-0.9077, -0.3205],\n",
            "         [-0.8944, -0.2902],\n",
            "         [-0.5134, -0.0288],\n",
            "         [-0.5134, -0.0288],\n",
            "         [-0.9127, -0.2222]]], grad_fn=<StackBackward>)\n",
            "torch.Size([3, 5, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}