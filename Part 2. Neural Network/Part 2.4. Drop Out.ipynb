{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 2.4. Drop Out.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnMQTEQmMBLA",
        "colab_type": "text"
      },
      "source": [
        "# Part 2.4. Drop Out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhNzutqQN0pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2e1A2d5N4TG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AcSVL5HMgNo",
        "colab_type": "text"
      },
      "source": [
        "# 1. Overfitting과 Underfitting\n",
        "\n",
        "![11-1.png](./img/11-1.png)\n",
        "\n",
        "오버피팅이란 해당 데이터에 너무 과하게 피팅이 된 경우를 말하고, 언더피팅은 너무 피팅이 안 되서 경향성을 제대로 파악하지 못한 경우를 말한다. 오버피팅이 되면 학습 데이터에는 높은 성능을 보이지만 테스트 데이터에는 낮은 성능을 보인다.\n",
        "\n",
        "![11-2.png](./img/11-2.png)\n",
        "\n",
        "학습 데이터에 오버피팅이 되버리면 새로운 데이터를 받아들였을 때 오버피팅이 덜 된 모델보다는 더 많은 에러를 발생시킨다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvPGzkZ6ND3L",
        "colab_type": "text"
      },
      "source": [
        "## 2. Drop Out\n",
        "\n",
        "![11-3.png](./img/11-3.png)\n",
        "\n",
        "학습을 진행하면서 각 layer에 존재하는 노드들을 무작위로 설정된 비율에 따라서 껐다 켰다를 반복하는 방법이다. 사용한다 결정된 노드들만을 가지고 학습을 한다. 이 때 반복 학습 시 매 iteration마다 사용되는 노드는 다르다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLnaNhyNN-ec",
        "colab_type": "text"
      },
      "source": [
        "## 3. MNIST Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7iWJrdkL85Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgPUPuUMODUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "drop_prob = 0.3         # 드롭아웃 비율 784 개 중 약 548개만 사용 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdMFAxhsOFZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWc1FpvnOHKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nn layers\n",
        "linear1 = torch.nn.Linear(784, 512, bias=True)\n",
        "linear2 = torch.nn.Linear(512, 512, bias=True)\n",
        "linear3 = torch.nn.Linear(512, 512, bias=True)\n",
        "linear4 = torch.nn.Linear(512, 512, bias=True)\n",
        "linear5 = torch.nn.Linear(512, 10, bias=True)\n",
        "relu = torch.nn.ReLU()\n",
        "dropout = torch.nn.Dropout(p=drop_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz2m7TJvOJ2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "ad384853-5eff-4fd3-be4d-c7b91222f767"
      },
      "source": [
        "# xavier initialization\n",
        "torch.nn.init.xavier_uniform_(linear1.weight)\n",
        "torch.nn.init.xavier_uniform_(linear2.weight)\n",
        "torch.nn.init.xavier_uniform_(linear3.weight)\n",
        "torch.nn.init.xavier_uniform_(linear4.weight)\n",
        "torch.nn.init.xavier_uniform_(linear5.weight)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0565,  0.0423, -0.0155,  ...,  0.1012,  0.0459, -0.0191],\n",
              "        [ 0.0772,  0.0452, -0.0638,  ...,  0.0476, -0.0638,  0.0528],\n",
              "        [ 0.0311, -0.1023, -0.0701,  ...,  0.0412, -0.1004,  0.0738],\n",
              "        ...,\n",
              "        [ 0.0334,  0.0187, -0.1021,  ...,  0.0280, -0.0583, -0.1018],\n",
              "        [-0.0506, -0.0939, -0.0467,  ..., -0.0554, -0.0325,  0.0640],\n",
              "        [-0.0183, -0.0123,  0.1025,  ..., -0.0214,  0.0220, -0.0741]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNJ86xZLOLyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model\n",
        "model = torch.nn.Sequential(linear1, relu, dropout,     # 매 layer에서 drop out\n",
        "                            linear2, relu, dropout,\n",
        "                            linear3, relu, dropout,\n",
        "                            linear4, relu, dropout,\n",
        "                            linear5).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLrBiVHCON35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxO3vt1UOPyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "548cf067-1098-4fb0-ba09-8367d640d473"
      },
      "source": [
        "# train\n",
        "total_batch = len(data_loader)\n",
        "model.train()    # 모델을 학습하는 데 사용하겠다 설정 그러므로 dropout은 True\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # reshape input image into [batch_size by 784]\n",
        "        # label is not one-hot encoded\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning finished')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost = 0.309896529\n",
            "Epoch: 0002 cost = 0.143717140\n",
            "Epoch: 0003 cost = 0.113897748\n",
            "Epoch: 0004 cost = 0.095177643\n",
            "Epoch: 0005 cost = 0.085126437\n",
            "Epoch: 0006 cost = 0.072515391\n",
            "Epoch: 0007 cost = 0.066215232\n",
            "Epoch: 0008 cost = 0.065225162\n",
            "Epoch: 0009 cost = 0.060729682\n",
            "Epoch: 0010 cost = 0.054089081\n",
            "Epoch: 0011 cost = 0.050674122\n",
            "Epoch: 0012 cost = 0.048585333\n",
            "Epoch: 0013 cost = 0.048006427\n",
            "Epoch: 0014 cost = 0.044697393\n",
            "Epoch: 0015 cost = 0.043174274\n",
            "Learning finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRNXxmsBOUVu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "70f1f9d4-1ac3-4441-8b71-7e37dd8d20b8"
      },
      "source": [
        "# test\n",
        "with torch.no_grad():\n",
        "    model.eval()    # 모델을 평가하는 데 사용하겠다 설정 그러므로 dropout은 False\n",
        "\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9767999649047852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}