{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 2.3. Weight Initialization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZigWLW7vDVVw",
        "colab_type": "text"
      },
      "source": [
        "# Part 2.3. Weight Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkDqkD2JJHo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fruB9p2YJI2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YWF7JOiDhvf",
        "colab_type": "text"
      },
      "source": [
        "## 1. Why Good Initialization\n",
        "\n",
        "![10-1.png](./img/10-1.png)\n",
        "\n",
        "weight를 어떻게 초기화하느냐에 따라 모델의 성능이 달라지는 것을 볼 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwkLBgjjFFMg",
        "colab_type": "text"
      },
      "source": [
        "## 2. RBM and DBM\n",
        "\n",
        "![10-2.png](./img/10-2.png)\n",
        "\n",
        "RBM(Restricted Boltzmann Machine)란 위에 처럼 layer 안의 노드 간에는 연결이 없고 서로 이웃한 layer의 노드들끼리는 fully-connected 되어있는 형태를 말한다.\n",
        "\n",
        "![10-3.png](./img/10-3.png)\n",
        "\n",
        "RBM은 한 layer 씩 쌓고 RBM으로 학습하고 그 하위 layer의 weight값들을 고정시키고 그 위에 다시 layer를 쌓는 과정을 반복하여 pre-training과정을 진행한다. 그 후에 실제 training(=fine tuning)을 진행하여 실제 weight값을 구하게 된다.\n",
        "\n",
        "하지만 해당 방법은 현재 잘 쓰이지 않고 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXtaKrgXG4cT",
        "colab_type": "text"
      },
      "source": [
        "## 3. Xavier and He Initialization\n",
        "layer의 특성에 따라 weight값을 초기화한다. $n_{in}$은 layer의 input의 개수, $n_{out}$은 layer의 output 개수를 말한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIa6dxJjJQsp",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### 3.1. Xavier Initialization\n",
        "#### Xavier Normal Initialization\n",
        "정규 분포 형태의 초기값을 갖는 것.\n",
        "\n",
        "$$W \\sim N(0, Var(W))$$\n",
        "$$Var(W) = \\sqrt{\\frac{2}{n_{in}+n_{out}}}$$\n",
        "\n",
        "#### Xavier Uniform Initialization\n",
        "연속 균등 분포 형태로 초기값을 갖는 것.\n",
        "\n",
        "$$W \\sim U(-\\frac{6}{n_{in}+n_{out}}, +\\frac{6}{n_{in}+n_{out}})$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13tFIVYqJsu7",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. He Initialization\n",
        "He초기값은 Xavier초기값과 달리 output의 개수를 사용하지 않는다. 그 외에는 Xavier랑 동일.\n",
        "\n",
        "#### He Normal Initialization\n",
        "$$W \\sim N(0, Var(W))$$\n",
        "$$Var(W) = \\sqrt{\\frac{2}{n_{out}}}$$\n",
        "\n",
        "#### He Uniform Initialization\n",
        "\n",
        "$$W \\sim U(-\\frac{6}{n_{in}}, +\\frac{6}{n_{in}})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJwDoI9cJxcl",
        "colab_type": "text"
      },
      "source": [
        "## 4. MNIST Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hZWFbMnDQgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnv47yT_J8YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "refPjXb6J4O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxmKLBSKADt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nn layers\n",
        "linear1 = torch.nn.Linear(784, 256, bias=True)\n",
        "linear2 = torch.nn.Linear(256, 256, bias=True)\n",
        "linear3 = torch.nn.Linear(256, 10, bias=True)\n",
        "relu = torch.nn.ReLU()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyhrIWttKDDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "0bf3ea53-3e46-4474-9590-92a3a4108edf"
      },
      "source": [
        "# xavier uniform initialization\n",
        "torch.nn.init.xavier_uniform_(linear1.weight)\n",
        "torch.nn.init.xavier_uniform_(linear2.weight)\n",
        "torch.nn.init.xavier_uniform_(linear3.weight)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0215, -0.0894,  0.0598,  ...,  0.0200,  0.0203,  0.1212],\n",
              "        [ 0.0078,  0.1378,  0.0920,  ...,  0.0975,  0.1458, -0.0302],\n",
              "        [ 0.1270, -0.1296,  0.1049,  ...,  0.0124,  0.1173, -0.0901],\n",
              "        ...,\n",
              "        [ 0.0661, -0.1025,  0.1437,  ...,  0.0784,  0.0977, -0.0396],\n",
              "        [ 0.0430, -0.1274, -0.0134,  ..., -0.0582,  0.1201,  0.1479],\n",
              "        [-0.1433,  0.0200, -0.0568,  ...,  0.0787,  0.0428, -0.0036]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azBO4wnzKEzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model\n",
        "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQWQ4ZABKLfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAte3OQXKNZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "15765958-0a5c-4170-8eaa-3667f935c4ae"
      },
      "source": [
        "# train\n",
        "total_batch = len(data_loader)\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # reshape input image into [batch_size by 784]\n",
        "        # label is not one-hot encoded\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning finished')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost = 0.249894276\n",
            "Epoch: 0002 cost = 0.094109461\n",
            "Epoch: 0003 cost = 0.060697529\n",
            "Epoch: 0004 cost = 0.043816913\n",
            "Epoch: 0005 cost = 0.031662427\n",
            "Epoch: 0006 cost = 0.027006302\n",
            "Epoch: 0007 cost = 0.021771355\n",
            "Epoch: 0008 cost = 0.017671170\n",
            "Epoch: 0009 cost = 0.016151655\n",
            "Epoch: 0010 cost = 0.014032764\n",
            "Epoch: 0011 cost = 0.013825929\n",
            "Epoch: 0012 cost = 0.012349785\n",
            "Epoch: 0013 cost = 0.012296054\n",
            "Epoch: 0014 cost = 0.009266987\n",
            "Epoch: 0015 cost = 0.009194419\n",
            "Learning finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48cYsUpkKPko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "7a8f1d0d-4fbe-46fa-edfc-d527fb85d89a"
      },
      "source": [
        "# test\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9821000099182129\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}